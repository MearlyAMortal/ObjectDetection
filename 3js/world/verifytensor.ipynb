{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=./yolov8n_web_model/model.json. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./yolov8n_web_model/model.json, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load YOLO model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./yolov8n_web_model/model.json\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust to your YOLO model path\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m yolo_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Path to the test folder\u001b[39;00m\n\u001b[1;32m     13\u001b[0m test_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tflabsfall24/lib/python3.10/site-packages/keras/src/saving/saving_api.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=./yolov8n_web_model/model.json. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./yolov8n_web_model/model.json, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLO model\n",
    "model_path = \"./yolov8n_web_model/model.json\"  # Adjust to your YOLO model path\n",
    "yolo_model = TFSMLayer(model_path, call_endpoint='serving_default')\n",
    "\n",
    "# Path to the test folder\n",
    "test_folder = \"./test\"\n",
    "\n",
    "# Confidence threshold for YOLO\n",
    "threshold = 0.1\n",
    "\n",
    "# Function to process a single image and tensor\n",
    "def process_image_and_tensor(image_path, tensor_path=None):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB').resize((640, 640))\n",
    "    image_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "    input_tensor = tf.convert_to_tensor(image_array, dtype=tf.float32)\n",
    "    input_tensor = tf.expand_dims(input_tensor, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Run inference with YOLO\n",
    "    predictions = yolo_model.predict(input_tensor)\n",
    "\n",
    "    # Post-process predictions\n",
    "    detections = []\n",
    "    for pred in predictions[0]:  # Assuming predictions[0] has [x, y, w, h, conf, class_probs...]\n",
    "        x, y, w, h, conf = pred[:5]\n",
    "        class_probs = pred[5:]\n",
    "        class_id = np.argmax(class_probs)\n",
    "        class_confidence = class_probs[class_id]\n",
    "\n",
    "        # Filter detections by confidence\n",
    "        if conf > threshold:\n",
    "            detections.append({\n",
    "                \"box\": [x, y, w, h],\n",
    "                \"confidence\": conf,\n",
    "                \"class_id\": class_id,\n",
    "                \"class_confidence\": class_confidence\n",
    "            })\n",
    "\n",
    "    # Print detections\n",
    "    print(f\"\\nDetections for {image_path}:\")\n",
    "    for det in detections:\n",
    "        print(det)\n",
    "\n",
    "    # Visualize detections\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    for det in detections:\n",
    "        x, y, w, h = det['box']\n",
    "        x_min, y_min = int(x - w / 2), int(y - h / 2)\n",
    "        x_max, y_max = int(x + w / 2), int(y + h / 2)\n",
    "        plt.gca().add_patch(plt.Rectangle((x_min, y_min), w, h, edgecolor='red', facecolor='none', linewidth=2))\n",
    "        plt.text(x_min, y_min - 5, f\"Class: {det['class_id']} ({det['confidence']:.2f})\", color='red')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detections for {os.path.basename(image_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Compare with saved tensor if available\n",
    "    if tensor_path:\n",
    "        with open(tensor_path, 'r') as f:\n",
    "            saved_tensor = np.array(json.load(f))\n",
    "        print(f\"Loaded saved tensor shape for {tensor_path}: {saved_tensor.shape}\")\n",
    "\n",
    "# Process all images and tensors in the folder\n",
    "for file_name in os.listdir(test_folder):\n",
    "    file_path = os.path.join(test_folder, file_name)\n",
    "\n",
    "    # Check if the file is an image\n",
    "    if file_name.endswith(\".png\") or file_name.endswith(\".jpg\"):\n",
    "        # Find corresponding tensor file\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        tensor_file = os.path.join(test_folder, f\"{base_name}.json\")\n",
    "        if os.path.exists(tensor_file):\n",
    "            process_image_and_tensor(file_path, tensor_file)\n",
    "        else:\n",
    "            process_image_and_tensor(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflabsfall24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
